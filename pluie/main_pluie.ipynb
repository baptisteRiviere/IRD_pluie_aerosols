{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation des pluies en Guyane\n",
    "\n",
    "Ce framework a pour objectif d'évaluer différentes estimation de la pluviométrie en Guyane\n",
    "\n",
    "Les sources des données utilisées sont :\n",
    "- vérité terrain MétéoFrance\n",
    "- images de température de brillance SSMIS produit par la NSIDC (API_NSIDC)\n",
    "- images de température de surface SEVIRI produit par meteosat (API_METEOSAT)\n",
    "- estimation IMERG produit par la NASA et JAXA (API_IMERG)\n",
    "  \n",
    "Les changements principaux à effectuer dans le code sont marqués par le mot clé TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reloading \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# modules du répertoire courant\n",
    "import ground_truth_rain as gt\n",
    "\n",
    "# modules du répertoire Images\n",
    "sys.path.insert(0, r'../Images')\n",
    "from Image import Image\n",
    "from File import File\n",
    "from Geotiff_Format import Geotiff_Format\n",
    "\n",
    "# modules du répertoire tools\n",
    "sys.path.insert(0, r'../tools')\n",
    "from tools import get_index,save_index,make_directory\n",
    "\n",
    "# modules du répertoire downloading\n",
    "sys.path.insert(0, r'../downloading/API_METEOSAT')\n",
    "from meteosat_download import download_SEVIRI_image\n",
    "sys.path.insert(0, r'../downloading/API_NSIDC')\n",
    "from SSMIS_download import download_SSMIS_image\n",
    "sys.path.insert(0, r'../downloading/API_IMERG')\n",
    "from IMERG_download import download_IMERG_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des variables principales\n",
    "\n",
    "On définit les chemins d'accès principaux afin d'obtenir les variables utiles dans tout le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### variables principales     #################################################################\n",
    "\n",
    "# TODO : chemin d'accès au dossier principal où les fichiers seront générés\n",
    "main_dir = make_directory(r\"../../data/estimation_rain\")\n",
    "\n",
    "# TODO : chemin d'accès au fichier json contenant les paramètres de la projection comme la résolution et l'emprise\n",
    "projection_path = r\"../../data/param_proj/param_guy.json\"\n",
    "\n",
    "# TODO : chemin d'accès au fichier csv contenant la vérité terrain\n",
    "gt_fn = r\"../../data/pluie_sol/gauges_guyane_1h_utc.csv\"\n",
    "\n",
    "##### gestion de l'index        #################################################################\n",
    "\n",
    "# l'index est un fichier json ou dictionnaire contenant pour chaque date les images correspondantes\n",
    "# il est utile pour télécharger et combiner les images d'une même date\n",
    "\n",
    "# TODO : remplir le chemin d'accès au fichier json index\n",
    "index_path = main_dir + r\"/acq_dates.json\"\n",
    "\n",
    "# TODO : Pour compléter les dates visées dans le format suivant\n",
    "target_dates = [\n",
    "    \"2020-05-03T12:00:00.000000+0000\",\n",
    "    \"2020-05-08T12:00:00.000000+0000\",\n",
    "    \"2020-05-15T12:00:00.000000+0000\",\n",
    "    \"2020-05-18T12:00:00.000000+0000\",\n",
    "    \"2020-05-26T12:00:00.000000+0000\",\n",
    "    \"2020-12-12T12:00:00.000000+0000\",\n",
    "    \"2020-12-29T12:00:00.000000+0000\"\n",
    "]\n",
    "\n",
    "# TODO : si l'index est utile à l'utilisation et qu'il n'est pas déjà mis en place,\n",
    "# décommenter les 2 lignes ci-dessous pour l'initialiser\n",
    "\n",
    "#index = {d.split(\" \")[0]:{\"target\":d} for d in target_dates} # initialisation des clés de l'index\n",
    "#save_index(index,index_path)   \n",
    "\n",
    "##### clés de téléchargement        #################################################################\n",
    "\n",
    "# TODO : pour le téléchargement des images\n",
    "# remplir le chemin d'accès aux fichiers contenant les clés des API\n",
    "path_API_meteosat_keys = r\"../../data/keys/eds.key\"         # deux lignes : voir meteosat pour les clés d'accès\n",
    "path_API_nsidc_keys = r\"../../data/keys/mdp_NSIDC.json\"     # {\"username\": \"<username>\",\"password\": \"<password>}\"\n",
    "\n",
    "# TODO : vérifier si besoin les variables suivantes\n",
    "##### initialisation des variables  #################################################################\n",
    "\n",
    "# chemin d'accès aux métadatas de la vérité terrain\n",
    "gt_mtd_fn = os.path.dirname(gt_fn) + r\"/gauges_guyane_metadata.csv\"\n",
    "\n",
    "# chemins d'accès aux dossiers où seront téléchargés les fichiers bruts \n",
    "# la taille de ces fichiers peut devenir assez importante, notamment pour les images SEVIRI\n",
    "SSMIS_src_dir = make_directory(r\"../../data/SSMIS/download\")\n",
    "SEVIRI_src_dir = make_directory(r\"../../data/SEVIRI/download\")\n",
    "IMERG_src_dir = make_directory(r\"../../data/IMERG/download\")\n",
    "\n",
    "# chemins d'accès aux dossiers où seront téléchargés les fichiers reprojetés\n",
    "SSMIS_proj_dir  = make_directory(main_dir + r\"/SSMIS\")\n",
    "SEVIRI_proj_dir = make_directory(main_dir + r\"/SEVIRI\")\n",
    "rr_dir          = make_directory(main_dir + r\"/rain_rate\")\n",
    "agr_dir         = make_directory(main_dir + r\"/agregation\")\n",
    "eval_dir        = make_directory(main_dir+r\"/evaluation\")\n",
    "\n",
    "# chargement de la projection\n",
    "projection = json.load(open(projection_path, \"r\", encoding=\"utf-8\")) \n",
    "\n",
    "# format principal des dates\n",
    "format = \"%Y-%m-%dT%H:%M:%S.%f%z\"\n",
    "\n",
    "# permet de rechercher les images SSMIS par itération sur différents paramètres\n",
    "SSMIS_parameters = { \n",
    "        \"freq\":     [\"91V\",         \"91V\",          \"91V\",          \"91V\"       ],\n",
    "        \"passage\":  [\"E\",           \"A\",            \"E\",            \"A\"         ],\n",
    "        \"capteur\":  [\"F17_SSMIS\",   \"F17_SSMIS\",    \"F16_SSMIS\",    \"F16_SSMIS\" ],\n",
    "        \"algo\":     [\"GRD\",         \"GRD\",          \"GRD\",          \"GRD\"       ],\n",
    "        \"grid\":     [\"N25km\",       \"N25km\",        \"N25km\",        \"N25km\"     ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des images par l'index\n",
    "\n",
    "L'index est un dictionnaire permettant d'accéder les chemins vers les différentes images par date, ce module permet de télécharger certaines images à partir des dates données dans l'index et de mettre celui-ci à jour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour les images SSMIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_SSMIS(attribute):\n",
    "    \"\"\"\n",
    "    Télécharge les données SSMIS, puis réalise leur extraction et leur projection\n",
    "    Les dates choisies sont les clés de l'index (variable globale index_path)\n",
    "    Un fichier déjà présent dans le dossier SSMIS_src_dir n'est pas téléchargé à nouveau\n",
    "    La recherche se fait par itérations sur certains paramètres (variable globale SSMIS_parameters) \n",
    "    L'index est automatiquement mis à jour\n",
    "    \n",
    "    Args:\n",
    "        attribute (string) : attribut à extraire de l'image\n",
    "    \"\"\"\n",
    "    index = get_index(index_path)\n",
    "    for d in index.keys(): # pour chaque date dans le\n",
    "        # téléchargement des données\n",
    "        tg_date = datetime.strptime(d,format)\n",
    "        retour = download_SSMIS_image(tg_date,SSMIS_src_dir,projection,SSMIS_parameters,path_API_nsidc_keys)\n",
    "        tg_freq = SSMIS_parameters[\"freq\"][0]\n",
    "        if retour: # un fichier a bien été téléchargé\n",
    "            src_filename,start_date,end_date = retour\n",
    "            file = File(src_filename) ; string_d = d[:10]\n",
    "            tif_filename = SSMIS_proj_dir + rf\"/SSMIS_{attribute}_{tg_freq}_{string_d}.tiff\"\n",
    "            file.project(projection,attribute,out_path=tif_filename) # projection\n",
    "            # inscription des chemins d'accès à l'index\n",
    "            index[d][f\"SSMIS_src_{tg_freq}\"] = src_filename\n",
    "            index[d][f\"start_date_{tg_freq}\"] = datetime.strftime(start_date,format)\n",
    "            index[d][f\"end_date_{tg_freq}\"] = datetime.strftime(end_date,format)\n",
    "            index[d][f\"SSMIS_tif_{tg_freq}\"] = tif_filename\n",
    "            save_index(index,index_path)\n",
    "        else:\n",
    "            print(f\"aucun fichier n'a été trouvé pour la date {d}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour les images SEVIRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_SEVIRI(attribute):\n",
    "    \"\"\"\n",
    "    Télécharge les données SEVIRI, puis réalise leur extraction et leur projection\n",
    "    Un fichier déjà présent dans le dossier SEVIRI_src_dir n'est pas téléchargé à nouveau\n",
    "    L'index est automatiquement mis à jour\n",
    "    \n",
    "    Args:\n",
    "        attribute (string) : attribut à extraire de l'image\n",
    "        SEVIRI_parameters (dict) : dictionnaire contenant les paramètres successifs à prendre en compte dans le téléchargement\n",
    "    \"\"\"\n",
    "    nb_files_per_period = 12\n",
    "    index = get_index(index_path)\n",
    "    arrays_SEVIRI = []\n",
    "    for d in index.keys():\n",
    "        index[d][\"IR_SEVIRI_source_files\"] = []\n",
    "        print(f\"recherche pour la date {d}\")\n",
    "        start_acq_date = datetime.strptime(index[d][\"start_date_91V\"],format)\n",
    "        end_acq_date = datetime.strptime(index[d][\"end_date_91V\"],format)\n",
    "        delta = timedelta(seconds=(end_acq_date - start_acq_date).total_seconds() / nb_files_per_period)\n",
    "        researched_dates = [start_acq_date + i*delta for i in range(nb_files_per_period)]\n",
    "        for res_d in researched_dates:\n",
    "            # téléchargement des données\n",
    "            retour = download_SEVIRI_image(res_d,SEVIRI_src_dir,path_API_meteosat_keys)\n",
    "            if retour: # un fichier a bien été téléchargé\n",
    "                src_filename,start_date,end_date = retour\n",
    "                index[d][\"IR_SEVIRI_source_files\"] = index[d][\"IR_SEVIRI_source_files\"] + [src_filename]\n",
    "                SEVIRI_file = File(src_filename)\n",
    "                img_proj = SEVIRI_file.project(projection,attribute)\n",
    "                arrays_SEVIRI.append(img_proj.array)\n",
    "        img_proj_agreg = Image(np.mean(np.array(arrays_SEVIRI),axis=0),img_proj.lons,img_proj.lats)\n",
    "        string_d = d[:10]\n",
    "        tif_filename = SEVIRI_proj_dir + rf\"/SEVIRI_TB_{attribute}_{string_d}.tiff\"\n",
    "        img_proj_agreg.save(projection,tif_filename)\n",
    "        index[d][f\"SEVIRI_tif_{attribute}\"] = tif_filename\n",
    "        save_index(index,index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mise en place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_SEVIRI(\"IR_108\")\n",
    "#download_SSMIS(\"TB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrégation des images par l'index\n",
    "\n",
    "Il est alors possible d'agréger les images conservées dans l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregation_geotiff(out_dir,key,mode=\"mean\"):\n",
    "    \"\"\"\n",
    "    premet d'agréger les images correspondantes à toutes les dates contenues dans l'index \n",
    "\n",
    "    Args:\n",
    "        out_dir (string) : chemin vers le répertoire de sortie\n",
    "        key (string) : clé de l'image à agréger\n",
    "        mode (\"mean\" ou \"sum\") : mode d'agrégation (Default \"mean\")\n",
    "\n",
    "    Return:\n",
    "        img_output (Image) : Image agrégée\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    index = get_index(index_path)\n",
    "    for d in index.keys(): # récupération des images\n",
    "        try:\n",
    "            file = File(index[d][key])\n",
    "            if file.format != Geotiff_Format:\n",
    "                print(\"le fichier doit être en format Geotiff\")\n",
    "                raise\n",
    "            img = file.getImage(1)\n",
    "            arrays.append(img.array)\n",
    "        except KeyError:\n",
    "            print(f\"le fichier correspondant à la date {d} n'a pas été trouvé pour la clé {key}\")\n",
    "    \n",
    "    lons,lats = img.lons, img.lats\n",
    "    if mode == \"mean\":\n",
    "        output = np.nanmean(np.array(arrays),axis=0)\n",
    "    else:\n",
    "        output = np.sum(np.array(arrays),axis=0)\n",
    "    img_output = Image(output, lons, lats)\n",
    "    img_output.save(projection,out_dir + rf\"/{key}_agreg.tiff\")\n",
    "    return img_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unitaire\n",
    "\n",
    "for key in [\"SSMIS_tif_91V\",\"SEVIRI_tif_IR_087\"]:\n",
    "    img_agreg = agregation_geotiff(agr_dir,key)\n",
    "img_var_IR = img_agreg.computeVar()\n",
    "img_var_IR.save(projection,agr_dir + rf\"/{key}_agreg_var.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction pixels image - vérité terrain\n",
    "\n",
    "Ce module permet de mettre en relation une image ou plusieurs avec la vérité terrain.\n",
    "\n",
    "C'est à dire d'extraire les valeurs des capteurs sur le pixel correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gt_pixel_from_image(filename,attribute,cols=False):\n",
    "    \"\"\"\n",
    "    Pour une image et pour les capteurs séléctionnés\n",
    "    associe la valeur du pixel correspondant à la localisation du capteur \n",
    "    et renvoie les listes contenant ces valeurs\n",
    "\n",
    "    Args:\n",
    "        filename (string) : nom du fichier dont on veut extraire les données\n",
    "        attribute (float) : attribut de l'image à extraire\n",
    "        cols (bool, list) : liste des index des stations à prendre en compte, les considère toutes si False (Default False)\n",
    "    \n",
    "    Return:\n",
    "        final_df (pandas dataframe) : dataframe contenant les valeurs extraites\n",
    "    \"\"\"\n",
    "\n",
    "    # initialisation du dataframe contenant le résultat\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    # récupération de l'image associée au fichier et des dates d'acquisition\n",
    "    file = File(filename)\n",
    "    image = file.project(projection,attribute)\n",
    "    start_date,end_date = file.getAcqDates()\n",
    "\n",
    "    # récupération de la vérité terrain et agrégation\n",
    "    gt_1h_df = pd.read_csv(gt_fn)\n",
    "    mtd_df = pd.read_csv(gt_mtd_fn)\n",
    "    gt_1h_extr_df = gt.extract(gt_1h_df,start_date,end_date)\n",
    "    \n",
    "    if isinstance(gt_1h_extr_df, pd.DataFrame):\n",
    "        gt_agreg_df = gt_1h_extr_df.sum(skipna=True,min_count=1)\n",
    "    else:\n",
    "        gt_agreg_df = gt_1h_extr_df\n",
    "\n",
    "    # mise en place des colones à parcourir\n",
    "    if cols == False:\n",
    "        cols = gt_1h_df.columns[1:]\n",
    "    elif type(cols[0]) == int:\n",
    "        cols = [gt_1h_df.columns[col_idx] for col_idx in cols]\n",
    "\n",
    "    # pour chaque station on associe la valeur du pixel à l'agrégation des mesures sur la période d'acquisition\n",
    "    for col in cols:\n",
    "        num = mtd_df.loc[mtd_df[\"Numéro\"]==int(col)][\"Numéro\"].array[0]\n",
    "        name = mtd_df.loc[mtd_df[\"Numéro\"]==int(col)][\"Nom\"].array[0]\n",
    "        lat = mtd_df.loc[mtd_df[\"Numéro\"]==int(col)][\"lat\"].array[0]\n",
    "        lon = mtd_df.loc[mtd_df[\"Numéro\"]==int(col)][\"lon\"].array[0]\n",
    "        lats, lons = image.lats.T[0], image.lons[0]\n",
    "        idx_lat,idx_lon = (np.abs(lats - lat)).argmin(), (np.abs(lons - lon)).argmin()\n",
    "        pixel_value = image.array[idx_lat][idx_lon] ; true_rain_value = gt_agreg_df.loc[col]\n",
    "        if (not np.isnan(true_rain_value)) and (not np.isnan(pixel_value)):\n",
    "            # vérification que l'une des valeur n'est pas nulle (manque de donnée par exemple)\n",
    "            df = pd.DataFrame(columns=[\"date\",\"nom capteur\",\"id capteur\",\"lon\",\"lat\",\"VT\",\"pixel\"])\n",
    "            df.loc[\"total\"] = [start_date,name,num,lon,lat,true_rain_value,pixel_value]\n",
    "            final_df = pd.concat([final_df,df],ignore_index=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def combine_gt_pixel_from_index(key,attribute=1,sdk=\"start_date\",edk=\"start_date\",cols=False):\n",
    "    \"\"\"\n",
    "    Pour une certaine image de chaque date de l'index, et pour les capteurs séléctionnés\n",
    "    associe la valeur du pixel correspondant à la localisation du capteur \n",
    "    et renvoie les listes contenant ces valeurs\n",
    "\n",
    "    Args:\n",
    "        key (string) : clé correspondant à l'image dont on veut extraire les données\n",
    "        attribute (int or string) : attribut de l'image à extraire (Default 1)\n",
    "        sdk (string) : start date key, correspond à la clé indiquant le début de la période d'acquisition de l'Image\n",
    "        edk (string) : end date key, correspond à la clé indiquant la fin de la période d'acquisition de l'Image\n",
    "        cols (bool, list) : liste des index des stations à prendre en compte, les considère toutes si False (Default False)\n",
    "    \n",
    "    Return:\n",
    "        final_df (pandas dataframe) : dataframe contenant les valeurs extraites\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "    index = get_index(index_path)\n",
    "    true_rain_sample,pixel_values_sample = [],[]\n",
    "    for d in index.keys():\n",
    "        try:\n",
    "            file = File(index[d][key])\n",
    "            result_df = combine_gt_pixel_from_image(file,attribute,cols)\n",
    "            final_df = pd.concat([final_df,result_df],ignore_index=True)\n",
    "        except KeyError:\n",
    "            print(f\"le fichier correspondant à la date {d} n'a pas été trouvé pour la clé {key}\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Baptiste\\Documents\\ENSG\\stage\\IRD_pluie_aerosols\\pluie\\main_pluie.ipynb Cellule 18\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# test unitaire\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m netcdf_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../data/IMERG/download/3B-DAY-L.MS.MRG.3IMERG.20220404-S000000-E235959.V06.nc4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result_df \u001b[39m=\u001b[39m combine_gt_pixel_from_image(netcdf_path,\u001b[39m\"\u001b[39;49m\u001b[39mHQprecipitation\u001b[39;49m\u001b[39m\"\u001b[39;49m,cols\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m6\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(result_df)\n",
      "\u001b[1;32mc:\\Users\\Baptiste\\Documents\\ENSG\\stage\\IRD_pluie_aerosols\\pluie\\main_pluie.ipynb Cellule 18\u001b[0m in \u001b[0;36mcombine_gt_pixel_from_image\u001b[1;34m(filename, attribute, cols)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mPour une image et pour les capteurs séléctionnés\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39massocie la valeur du pixel correspondant à la localisation du capteur \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    final_df (pandas dataframe) : dataframe contenant les valeurs extraites\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# initialisation du dataframe contenant le résultat\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m final_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# récupération de l'image associée au fichier et des dates d'acquisition\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Baptiste/Documents/ENSG/stage/IRD_pluie_aerosols/pluie/main_pluie.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m file \u001b[39m=\u001b[39m File(filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# test unitaire\n",
    "\n",
    "netcdf_path = r\"../../data/IMERG/download/3B-DAY-L.MS.MRG.3IMERG.20220404-S000000-E235959.V06.nc4\"\n",
    "\n",
    "result_df = combine_gt_pixel_from_image(netcdf_path,\"HQprecipitation\",cols=[1,2,6])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison images - vérité terrain\n",
    "\n",
    "Ce module permet de comparer les images avec la vérité terrain en calculant les métriques associées\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_gt_pixel_values(ground_list,estim_list,indice_corr=\"Pearson\",savefig=False,quiet=False):\n",
    "    \"\"\"\n",
    "    Compare une liste d'estimation d'une valeur avec une liste vérité terrain\n",
    "    Les métriques calcuées sont le coefficient de corrélation, le RMSE et le BIAS\n",
    "\n",
    "    Args :\n",
    "        ground_list (list) : liste des valeurs de vérité terrain\n",
    "        estim_list (list) : liste des valeurs estimée\n",
    "        indice_corr (\"Pearson\" ou \"Spearman\") : type du coefficient de corrélation calculé (Default \"Pearson\")\n",
    "        savefig (Bool - string) : si non faux, enregistre la figure avec le chemin savefig\n",
    "\n",
    "    Return :\n",
    "        corr (float) : coefficient de corrélation\n",
    "        RMSE (float) : Root Mean Square Error - moyenne des erreurs quadratiques\n",
    "        BIAS (float) : biais\n",
    "    \"\"\"\n",
    "    ground_list,estim_list = np.array(ground_list),np.array(estim_list)\n",
    "    xmin,xmax,attributes = 260,290,False\n",
    "\n",
    "    if indice_corr == \"Pearson\":\n",
    "        corr, _ = pearsonr(ground_list, estim_list)\n",
    "    elif indice_corr == \"Spearman\":\n",
    "        corr, _ = spearmanr(ground_list, estim_list)\n",
    "    RMSE = np.sqrt(np.sum((ground_list-estim_list)**2)/len(ground_list))\n",
    "    BIAS = np.sum(estim_list-ground_list) / np.sum(ground_list)\n",
    "\n",
    "    \n",
    "    if attributes:\n",
    "        color_list = [\"red\",\"green\",\"blue\",\"orange\",\"yellow\",\"pink\",\"black\",\"purple\",\"beige\",\"brown\",\"gray\",\"cyan\"]\n",
    "        colors = [color_list[np.where(np.unique(attributes)==loc)[0][0]] for loc in attributes]\n",
    "        plt.scatter(ground_list,estim_list,c=colors,s=60, alpha=0.8)\n",
    "        for i in range(len(np.unique(attributes))):\n",
    "            print(color_list[i],\"\\t\",np.unique(attributes)[i])\n",
    "    else:\n",
    "        plt.scatter(ground_list,estim_list,s=50,alpha=0.8)\n",
    "    plt.grid()\n",
    "    if savefig:\n",
    "        plt.savefig(savefig, dpi=500)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f\"CC {indice_corr} = {round(corr,3)}\")\n",
    "        print(f\"RMSE = {round(RMSE,3)}\")\n",
    "        print(f\"BIAS = {round(BIAS,3)}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return corr,RMSE,BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unitaire\n",
    "\n",
    "savefig = r\"../../rapports/images/rel_TBIR097-rain_0520.png\"\n",
    "\n",
    "#SEVIRI_IR_097_tif - SSMIS_tif_91V\n",
    "key = \"SSMIS_tif_91V\"\n",
    "true_rain,estim_rain,locations = combine_gt_pixel_from_index(key,edk=\"end_date_91V\",sdk=\"start_date_91V\")\n",
    "\n",
    "compare_gt_pixel_values(true_rain,estim_rain,indice_corr=\"Spearman\",savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place téléchargement et formattage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_formatting(image_name,start_period,end_period,attribute,nb_dates=False,shuffle=False):\n",
    "    \"\"\"\n",
    "    Télécharge un certain nombre d'images sur la période donnée\n",
    "    extrait la valeur de ses pixels avec la vérité terrain\n",
    "    retourne un jeu de données formaté\n",
    "\n",
    "    Args :\n",
    "        image_name (string) : image dont on veut comparer les pixels\n",
    "        start_period (datetime) : borne inférieur de la période étudiée\n",
    "        end_period (datetime) : borne supérieure de la période étudiée\n",
    "        attribute (string) : attribut de l'image à extraire\n",
    "        f_model (bool ou function) : fonction à appliquer à l'image pour générer une estimation, compare l'image elle-même si False (Default False)\n",
    "        nb_dates (Bool, int) : si entier, limite le nombre de dates générées (Default False)\n",
    "        shuffle (Bool) : si vrai, mélange la liste des dates, si le nombre de dates est limité cela équivaut à un tirage aléatoire\n",
    "\n",
    "    Return :\n",
    "        final_df (pandas dataframe) : dataframe contenant l'ensemble des valeurs extraites\n",
    "    \"\"\"\n",
    "\n",
    "    # initialisation du dataframe\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    # lecture et extraction du fichier de la vérité terrain entre les deux dates\n",
    "    # pour obtenir la liste des dates\n",
    "    gt_1h_df = pd.read_csv(gt_fn)\n",
    "    rain_extr_df = gt.extract(gt_1h_df,start_period,end_period)\n",
    "    rain_extr_df['time'] = pd.to_datetime(rain_extr_df['time'],utc=True) \n",
    "    rain_extr_df.set_index(\"time\",inplace=True)\n",
    "    rain_extr_df = rain_extr_df.resample(\"D\").sum()\n",
    "\n",
    "    # extraction des dates\n",
    "    dates = rain_extr_df.index.array\n",
    "    \n",
    "    # tirage aléatoire des dates\n",
    "    if shuffle:\n",
    "        random.seed(70)\n",
    "        random.shuffle(dates)\n",
    "    \n",
    "    # restriction à certaines dates\n",
    "    if nb_dates:\n",
    "        dates = dates[:nb_dates]\n",
    "    \n",
    "    # itération sur les dates\n",
    "    for d in dates:\n",
    "        result_df = download_and_combine(d,image_name,attribute)\n",
    "        final_df = pd.concat([final_df,result_df],ignore_index=True)\n",
    "        \n",
    "    return final_df\n",
    "    \n",
    "\n",
    "def download_and_combine(d,image_name,attribute,cols=False):\n",
    "    if image_name == \"SEVIRI\":\n",
    "        result = download_SEVIRI_image(d,SEVIRI_src_dir,path_API_meteosat_keys)\n",
    "    elif image_name == \"SSMIS\":\n",
    "        result = download_SSMIS_image(d,SSMIS_src_dir,projection,SSMIS_parameters,path_API_nsidc_keys,quiet=True)\n",
    "    elif image_name == \"IMERG\":\n",
    "        result = download_IMERG_image(d,IMERG_src_dir,quiet=True)\n",
    "    else:\n",
    "        result = False\n",
    "    \n",
    "    if result == False:\n",
    "        print(f\"aucune image n'a pu être téléchargée pour la date {d}\")\n",
    "        return False\n",
    "    else:\n",
    "        (fn,start,end) = result\n",
    "        # estimation de la pluie à partir du modèle appliqué à l'image\n",
    "        result_df = combine_gt_pixel_from_image(fn,attribute,cols)\n",
    "        return result_df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unitaire\n",
    "\n",
    "start_period = datetime(2019,1,1,tzinfo=timezone.utc)\n",
    "end_period = start_period + timedelta(days=31)\n",
    "\n",
    "main_formatting(\"SSMIS\",start_period,end_period,\"TB\",nb_dates=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement et préparation des données à analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2016,1,1,tzinfo=timezone.utc)\n",
    "end = datetime(2020,12,31,tzinfo=timezone.utc)\n",
    "\n",
    "image_name, attribute = \"IMERG\",\"HQprecipitation\"\n",
    "\n",
    "final_df = main_formatting(\n",
    "    image_name=image_name,\n",
    "    start_period=start,\n",
    "    end_period=end,\n",
    "    attribute=attribute,\n",
    "    nb_dates=False\n",
    "    )\n",
    "\n",
    "final_df.to_csv(eval_dir + rf\"/comparaison_{image_name}-VT_2016-2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = eval_dir + rf\"/comparaison_IMERG-VT_2016-2020.csv\"\n",
    "df = pd.read_csv(df_filename)\n",
    "indice_corr = \"Pearson\"\n",
    "df[\"month\"] = pd.DatetimeIndex(df['date']).month\n",
    "\n",
    "stat_df = pd.DataFrame(columns=[\"nb_points\",\"corr\",\"RMSE\",\"BIAS\",\"rain_mean\",\"rain_std\",\"rain_median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison de l'ensemble des données\n",
    "true_rain,pixel_values = df[\"VT\"].values,df[\"pixel\"].values\n",
    "savefig = eval_dir + rf\"/comparaison_IMERG-VT_2016-2020.png\"\n",
    "corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=savefig)\n",
    "\n",
    "stat_df.loc[\"2016-2020\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison par capteur\n",
    "for captor_name in np.unique(df[\"nom capteur\"].values):\n",
    "    df_capt = df.loc[df[\"nom capteur\"]==captor_name]\n",
    "    true_rain,pixel_values = df_capt[\"VT\"].values,df_capt[\"pixel\"].values\n",
    "    corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=False,quiet=True)\n",
    "    stat_df.loc[f\"2016-2020_{captor_name}\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]\n",
    "\n",
    "print(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison par mois\n",
    "for month in range(1,13):\n",
    "    df_month = df.loc[df[\"month\"]==month]\n",
    "    true_rain,pixel_values = df_month[\"VT\"].values,df_month[\"pixel\"].values\n",
    "    corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=False,quiet=True)\n",
    "    stat_df.loc[f\"2016-2020_month_{month}\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]\n",
    "\n",
    "print(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison par saison\n",
    "seasons = {\"avril-mai\":[4,5],\"dec-jan\":[12,1],\"sept-oct\":[9,10]}\n",
    "for s in seasons.keys():\n",
    "    df_seasons = df.loc[(df.iloc[i][\"month\"] in seasons[s] for i in range(len(df)))]\n",
    "    true_rain,pixel_values = df_seasons[\"VT\"].values,df_seasons[\"pixel\"].values\n",
    "    corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=False,quiet=True)\n",
    "    stat_df.loc[f\"2016-2020_season_{s}\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]\n",
    "print(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrégation des capteurs de Kourou uniquement\n",
    "df_Kourou = df.loc[(df.iloc[i][\"id capteur\"] in [97304001,97304003,97304005] for i in range(len(df)))]\n",
    "# agrégation des données par date (moyenne)\n",
    "df_Kourou['date'] = pd.to_datetime(df_Kourou['date'],utc=True) \n",
    "df_Kourou.set_index(\"date\",inplace=True)\n",
    "df_Kourou = df_Kourou.resample(\"D\").mean()\n",
    "df_Kourou=df_Kourou.dropna()\n",
    "# calcul des résultats\n",
    "true_rain,pixel_values = df_Kourou[\"VT\"].values,df_Kourou[\"pixel\"].values\n",
    "corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=False,quiet=True)\n",
    "stat_df.loc[f\"2016-2020 3stationsKourou\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]\n",
    "\n",
    "print(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrégation des données par mois (moyenne)\n",
    "df_monthly = df.copy()\n",
    "df_monthly['date'] = pd.to_datetime(df_monthly['date'],utc=True) \n",
    "df_monthly.set_index(\"date\",inplace=True)\n",
    "df_monthly = df_monthly.resample(\"M\").mean()\n",
    "df_monthly=df_monthly.dropna()\n",
    "true_rain,pixel_values = df_monthly[\"VT\"].values,df_monthly[\"pixel\"].values\n",
    "savefig = eval_dir + rf\"/comparaison_IMERG-VT_2016-2020_par_mois.png\"\n",
    "corr,RMSE,BIAS = compare_gt_pixel_values(true_rain,pixel_values,indice_corr=indice_corr,savefig=savefig)\n",
    "stat_df.loc[f\"2016-2020 par mois\"] = [len(true_rain),corr,RMSE,BIAS,np.mean(true_rain),np.std(true_rain),np.median(true_rain)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde des résultats\n",
    "stat_df.to_csv(eval_dir + rf\"/resultats_2016-2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction estimations Cayenne\n",
    "df_estim_Cay = df.loc[(df[\"id capteur\"] == 97307001)][[\"date\",\"pixel\"]]\n",
    "df_estim_Cay = df_estim_Cay.rename(columns={\"date\": \"time\", \"pixel\": 97307001})\n",
    "df_estim_Cay.set_index(\"time\",inplace=True)\n",
    "df_estim_Cay.to_csv(eval_dir + rf\"/estim_IMERG_cayenne.csv\",date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sat_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a52e5d84065f89c8195aea2272767e62fa59940dcf61368d5fc5f01a252f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
