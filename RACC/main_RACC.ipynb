{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# framework RACC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reloading \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# importing librairies\n",
    "from matplotlib.font_manager import json_load\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# importing modules from Images\n",
    "sys.path.insert(0, r'../Images')\n",
    "from Image import Image\n",
    "from File import File\n",
    "\n",
    "sys.path.insert(0, r'API_meteosat')\n",
    "from eds_get_nearest import get_nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dates and projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_path = r\"param_guy.json\"\n",
    "projection = json.load(open(projection_path, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "target_dates = [\n",
    "    \"2021-11-30 10:11:07\",\n",
    "    \"2021-12-01 20:00:54\",\n",
    "    \"2021-12-03 22:17:15\",\n",
    "    \"2021-12-04 22:03:37\",\n",
    "    \"2021-12-12 21:57:28\",\n",
    "    \"2021-12-13 21:44:29\",\n",
    "    \"2021-12-22 20:24:51\",\n",
    "    \"2021-12-25 21:50:50\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract SSMIS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_near_SSMI(dir,projection,tg_date=\"*\",freq=\"*\",pola=\"*\"):\n",
    "    year = str(tg_date.year)\n",
    "    days = (tg_date - datetime.datetime.strptime(year,\"%Y\")).days\n",
    "    delta_min, fn_min = np.iinfo(np.int32).max, None\n",
    "    for offset in [-1,0,1]:\n",
    "        fns = glob.glob(dir+ rf\"/*/*{year}{days+offset}-{freq}{pola}-*.nc\")\n",
    "        for fn in fns:\n",
    "            file = File(fn)\n",
    "            acq_date = file.getTime(projection,\"TB_time\").replace(tzinfo=None)\n",
    "            img = file.project(r\"../../data/test.tiff\",projection,\"TB\")\n",
    "            delta = (tg_date-acq_date).total_seconds()\n",
    "            try :\n",
    "                unique, counts = np.unique(img.array, return_counts=True)\n",
    "                zero_rate = dict(zip(unique, counts))[0]/(img.array.shape[0]*img.array.shape[1])\n",
    "            except KeyError:\n",
    "                zero_rate = 0\n",
    "            if (zero_rate < 0.1) and (np.abs(delta) < delta_min):\n",
    "                delta_min, fn_min = delta, fn\n",
    "    file = File(fn_min)\n",
    "    return file, file.getTime(projection,\"TB_time\")\n",
    "\n",
    "def download_SSMIS_images(dir,out_dir,dates,projection):\n",
    "    \"\"\"\n",
    "    sélectionne parmis les données SSMIS et IR les fichiers d'intérêt \n",
    "    télécharge ces fichiers puis les géoréférence à partir du dictionnaire projection\n",
    "    \"\"\"\n",
    "    acq_dates = {}\n",
    "    for date in dates:\n",
    "        dt = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\") ; freq = 91 ; pola = \"*\"\n",
    "        file,acq = search_near_SSMI(dir,projection,dt,freq,pola)\n",
    "        date_str = acq.strftime(\"%Y-%m-%d\")\n",
    "        filename = out_dir + rf\"/SSMIS_{date_str}.tiff\"\n",
    "        file.project(filename,projection,\"TB\")\n",
    "        acq_dates[filename] = acq.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    with open(out_dir+r'/acq_dates.json', 'w') as outfile:\n",
    "        json.dump(acq_dates, outfile)\n",
    "\n",
    "    #np.savetxt(, np.array(acq_dates), delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSMIS_dir = r\"../../data/SSMI/download_dec_2021\"\n",
    "SSMIS_out_dir = r\"../../data/RACC/decembre\"\n",
    "\n",
    "download_SSMIS_images(SSMIS_dir,SSMIS_out_dir,target_dates,projection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract Meteosat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_Meteosat_images(dates,path_download,path_unzipped):\n",
    "    for date in dates:\n",
    "        get_nearest(date,path_download,path_unzipped)\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "path_dowload=r\"../../data/IR\"\n",
    "path_unzipped=r\"../../data/RACC/decembre\"\n",
    "SSMIS_acq_dict = json.load(open(SSMIS_out_dir+r'/acq_dates.json', \"r\", encoding=\"utf-8\"))\n",
    "SSMIS_acq_dates = [datetime.datetime.strptime(SSMIS_acq_dict[k],\"%m/%d/%Y, %H:%M:%S\") for k in SSMIS_acq_dict.keys()]\n",
    "\n",
    "download_Meteosat_images(SSMIS_acq_dates,path_dowload,path_unzipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no man's land\n",
    "\n",
    "o\n",
    "\n",
    "o\n",
    "\n",
    "o\n",
    "\n",
    "o\n",
    "\n",
    "o\n",
    "\n",
    "o\n",
    "\n",
    "o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "from osgeo import gdal\n",
    "a = r\"../../data/SSMI/download_dec_2021\\238356902\\NSIDC-0630-EASE2_N25km-F18_SSMIS-2021333-91V-E-GRD-CSU_ICDR-v1.5.nc\"\n",
    "ds = gdal.Open(\"NETCDF:{0}:{1}\".format(a, \"TB_time\"))\n",
    "print(ds.GetGeoTransform())\n",
    "\"\"\"\n",
    "\n",
    "# ex code\n",
    "def selection_dir(dir,projection,attribute,zero_rate=0.1):\n",
    "    paths = glob.glob(dir + \"*/*.nc\")\n",
    "    out_dict = {}\n",
    "    for path in paths:\n",
    "        file = File(path)\n",
    "        image = file.project(\"temporary.tiff\",projection,attribute)\n",
    "        arr = image.array\n",
    "        try :\n",
    "            unique, counts = np.unique(arr, return_counts=True)\n",
    "            zero_rate = dict(zip(unique, counts))[0]/(arr.shape[0]*arr.shape[1])\n",
    "        except KeyError:\n",
    "            zero_rate = 0\n",
    "        if zero_rate < 0.1:\n",
    "            date = file.getTime(projection,f\"{attribute}_time\")\n",
    "            date = date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            out_dict[date] = path\n",
    "    with open(dir+\"dates.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(out_dict, f, ensure_ascii=False, indent=4)\n",
    "    return out_dict\n",
    "\n",
    "def download_IR(filenames,projection,attribute):\n",
    "    for fn in filenames:\n",
    "        file = File(fn)\n",
    "        date = fn.split(\"-\")[-2]\n",
    "        yyyy,mm,dd = date[:4],date[4:6],date[6:8]\n",
    "        file.project(rf\"../data/IR/agregation/{attribute}_{yyyy}-{mm}-{dd}.tiff\",projection,attribute)\n",
    "    \"\"\"\n",
    "    file = File(fn)\n",
    "    download_all(file,r\"../data/IR/results/IR{\")\n",
    "    \"\"\"\n",
    "\n",
    "def aggregation(projection,out_name,images=[],dir=False,mode=\"mean\"):\n",
    "    if dir:\n",
    "        images = []\n",
    "        filenames = glob.glob(rf\"{dir}*.tiff\")\n",
    "        for fn in filenames:\n",
    "            file = File(fn)\n",
    "            images.append(file.getImage(1).array)\n",
    "            lons,lats = file.getImage(1).lons, file.getImage(1).lats\n",
    "    if mode == \"mean\":\n",
    "        output = np.mean(np.array(images),axis=0)\n",
    "    else:\n",
    "        output = np.sum(np.array(images),axis=0)\n",
    "    img_output = Image(output, lons, lats)\n",
    "    img_output.save(projection,out_name)\n",
    "    \n",
    "def search_near_SSMI(dir,projection,tg_date=\"*\",freq=\"*\",pola=\"*\"):\n",
    "    year = str(tg_date.year)\n",
    "    days = (tg_date - datetime.datetime.strptime(year,\"%Y\")).days\n",
    "    delta_min, fn_min = np.iinfo(np.int32).max, None\n",
    "    for offset in [-1,0,1]:\n",
    "        fns = glob.glob(dir+ rf\"/*/*{year}{days+offset}-{freq}{pola}-*.nc\")\n",
    "        for fn in fns:\n",
    "            file = File(fn)\n",
    "            acq_date = file.getTime(projection,\"TB_time\").replace(tzinfo=None)\n",
    "            img = file.project(r\"../data/test.tiff\",projection,\"TB\")\n",
    "            delta = (tg_date-acq_date).total_seconds()\n",
    "            try :\n",
    "                unique, counts = np.unique(img.array, return_counts=True)\n",
    "                zero_rate = dict(zip(unique, counts))[0]/(img.array.shape[0]*img.array.shape[1])\n",
    "            except KeyError:\n",
    "                zero_rate = 0\n",
    "            if (zero_rate < 0.1) and (np.abs(delta) < delta_min):\n",
    "                delta_min, fn_min = delta, fn\n",
    "    file = File(fn_min)\n",
    "    return file, file.getTime(projection,\"TB_time\")\n",
    "\n",
    "def prepare_data_RACC(main_dir,dates,projection):\n",
    "    \"\"\"\n",
    "    sélectionne parmis les données SSMIS et IR les fichiers d'intérêt \n",
    "    télécharge ces fichiers puis les géoréférence de la même manière\n",
    "    aggrège les données et calcule la variance des images IR\n",
    "    \"\"\"\n",
    "    SSMI_imgs = []\n",
    "    for date in dates:\n",
    "        dt = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\") ; freq = 91 ; pola = \"*\"\n",
    "        file,acq = search_near_SSMI(\"../data/SSMI/download_dec_2021\",projection,dt,freq,pola)\n",
    "        date_str = acq.strftime(\"%Y-%m-%d\")\n",
    "        img = file.project(rf\"../data/RACC/produced/SSMIS_{date_str}.tiff\",projection,\"TB\")\n",
    "        SSMI_imgs.append(img.array)\n",
    "    aggregation(projection,rf\"../data/RACC/produced/SSMIS_agrege.tiff\",SSMI_imgs)\n",
    "\n",
    "\n",
    "\n",
    "    prepare_data_RACC(dir,dates,projection)\n",
    "    \n",
    "\n",
    "    #download_IR(glob.glob(r\"../data/IR/*.nat\"),projection,\"IR_087\")\n",
    "\n",
    "    #aggregation(r\"../data/SSMI/agregation/\",projection,\"mean\")\n",
    "    #aggregation(r\"../data/IR/agregation/\",projection,\"mean\",True)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dates_dir = json.load(open(r\"../data/SSMI/dates.json\", \"r\", encoding=\"utf-8\"))\n",
    "    \n",
    "    for d in dates:\n",
    "        filename = dates_dir[d].split(\"-\")\n",
    "        filename[-5] = \"19V\"\n",
    "        f = '-'.join(filename)\n",
    "        print(f)\n",
    "    #download_SSMI_from_json(f\"{dir}dates.json\",dates,projection)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    #attributes = ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] \n",
    "    attributes = ['IR_087']\n",
    "    for att in attributes:\n",
    "        out_path = rf\"../data/test_seg/Meteosat_{att}.tiff\"\n",
    "        compute_var_path = rf\"../data/test_seg/Meteosat_{att}_var.tiff\"\n",
    "        values = convert_nat(nat_path,out_path,proj_path,att,compute_var_path)\n",
    "\n",
    "         for date in dates_dir.keys():\n",
    "        dates_list.append(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\"))\n",
    "    dates = matplotlib.dates.date2num(dates_list)\n",
    "    y = [1 for i in range(len(dates_list))]\n",
    "    plt.plot_date(dates,y)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    dates_list = list(dates_dir.keys())\n",
    "    dates_list.sort()\n",
    "    print(dates_list)\n",
    "    \"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sat_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a52e5d84065f89c8195aea2272767e62fa59940dcf61368d5fc5f01a252f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
